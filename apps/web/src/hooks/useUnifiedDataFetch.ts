import { useCallback } from 'react'
import { useQueryClient } from '@tanstack/react-query'
import { enedisApi } from '@/api/enedis'
import { logger } from '@/utils/logger'
import toast from 'react-hot-toast'
import type { PDL } from '@/types/api'
import { useDataFetchStore } from '@/stores/dataFetchStore'
import { useCacheBroadcast } from './useCacheBroadcast'

interface UseUnifiedDataFetchParams {
  selectedPDL: string
  selectedPDLDetails: PDL | undefined
  allPDLs: PDL[]
  /** Context de la page pour d√©terminer quelles donn√©es r√©cup√©rer */
  pageContext: 'consumption' | 'production' | 'all'
}

export function useUnifiedDataFetch({
  selectedPDL,
  selectedPDLDetails,
  allPDLs,
  pageContext,
}: UseUnifiedDataFetchParams) {
  const queryClient = useQueryClient()
  const { updateConsumptionStatus, updateProductionStatus, resetLoadingStatus } = useDataFetchStore()
  const { broadcast } = useCacheBroadcast()

  const fetchAllData = useCallback(async () => {
    if (!selectedPDL || !selectedPDLDetails) {
      toast.error('Veuillez s√©lectionner un PDL')
      return
    }

    // Reset all statuses
    resetLoadingStatus()

    // Calculate dates using LOCAL time for user's perspective (France timezone)
    // This ensures that at 0h30 local time, "yesterday" is still the previous calendar day
    const now = new Date()
    const yesterday = new Date(
      now.getFullYear(),
      now.getMonth(),
      now.getDate() - 1,
      12, 0, 0, 0  // Use noon to avoid DST edge cases
    )

    const today = new Date(
      now.getFullYear(),
      now.getMonth(),
      now.getDate(),
      12, 0, 0, 0
    )

    const threeYearsAgo = new Date(
      yesterday.getFullYear(),
      yesterday.getMonth(),
      yesterday.getDate() - 1095,
      12, 0, 0, 0
    )

    const twoYearsAgo = new Date(
      today.getFullYear() - 2,
      today.getMonth(),
      today.getDate(),
      12, 0, 0, 0
    )

    const formatDate = (date: Date) => {
      return date.getFullYear() + '-' +
             String(date.getMonth() + 1).padStart(2, '0') + '-' +
             String(date.getDate()).padStart(2, '0')
    }

    const endDate = formatDate(yesterday)
    const startDate3y = formatDate(threeYearsAgo)
    const startDate2y = formatDate(twoYearsAgo)

    logger.log('Starting unified data fetch:', {
      pdl: selectedPDL,
      pageContext,
      hasConsumption: selectedPDLDetails.has_consumption,
      hasProduction: selectedPDLDetails.has_production,
      linkedProductionPdl: selectedPDLDetails.linked_production_pdl_id,
    })

    // Prepare all fetch promises to run in parallel
    const fetchPromises: Promise<void>[] = []

    // Determine what data to fetch based on page context
    const shouldFetchConsumption = (pageContext === 'consumption' || pageContext === 'all') && selectedPDLDetails.has_consumption

    // On consumption page, also fetch production if PDL has production capability (direct or linked)
    const hasProductionCapability = selectedPDLDetails.has_production || !!selectedPDLDetails.linked_production_pdl_id
    const shouldFetchProduction = pageContext === 'production' || pageContext === 'all' || (pageContext === 'consumption' && hasProductionCapability)

    logger.log('Data fetch decisions:', { shouldFetchConsumption, shouldFetchProduction, hasProductionCapability })

    // === CONSUMPTION DATA ===
    if (shouldFetchConsumption) {
      // Invalidate existing consumption queries
      queryClient.invalidateQueries({ queryKey: ['consumptionDaily', selectedPDL] })
      queryClient.invalidateQueries({ queryKey: ['maxPower', selectedPDL] })

      // Fetch consumption daily data (3 years)
      updateConsumptionStatus({ daily: 'loading' })
      fetchPromises.push(
        (async () => {
          try {
            logger.log(`Fetching consumption daily: ${startDate3y} ‚Üí ${endDate}`)
            const dailyData = await enedisApi.getConsumptionDaily(selectedPDL, {
              start: startDate3y,
              end: endDate,
              use_cache: true,
            })

            if (dailyData?.success) {
              queryClient.setQueryData(['consumptionDaily', selectedPDL], dailyData)
              updateConsumptionStatus({ daily: 'success' })
              logger.log('Consumption daily data fetched successfully')
            } else {
              updateConsumptionStatus({ daily: 'error' })
            }
          } catch (error: any) {
            logger.log('Error fetching consumption daily:', error)
            updateConsumptionStatus({ daily: 'error' })
            toast.error(`Erreur donn√©es quotidiennes de consommation: ${error?.response?.data?.error?.message || error.message}`)
          }
        })()
      )

      // Fetch max power data (3 years)
      updateConsumptionStatus({ powerMax: 'loading' })
      fetchPromises.push(
        (async () => {
          try {
            logger.log(`Fetching max power: ${startDate3y} ‚Üí ${endDate}`)
            const powerData = await enedisApi.getMaxPower(selectedPDL, {
              start: startDate3y,
              end: endDate,
              use_cache: true,
            })

            if (powerData?.success) {
              queryClient.setQueryData(['maxPower', selectedPDL], powerData)
              updateConsumptionStatus({ powerMax: 'success' })
              logger.log('Max power data fetched successfully')
            } else {
              updateConsumptionStatus({ powerMax: 'error' })
            }
          } catch (error: any) {
            logger.log('Error fetching max power:', error)
            updateConsumptionStatus({ powerMax: 'error' })
            // Don't show error for power max - it's optional
          }
        })()
      )

      // Fetch consumption detail batch (2 years)
      updateConsumptionStatus({ detail: 'loading', detailProgress: { current: 0, total: 1 } })
      fetchPromises.push(
        (async () => {
          try {
            logger.log(`Fetching consumption detail batch: ${startDate2y} ‚Üí ${endDate}`)
            const batchData = await enedisApi.getConsumptionDetailBatch(selectedPDL, {
              start: startDate2y,
              end: endDate,
              use_cache: true,
            })

            if (batchData?.success && (batchData as any)?.data?.meter_reading?.interval_reading) {
              const readings = (batchData as any).data.meter_reading.interval_reading

              // Deduplicate readings using a Map with timestamp as key
              const uniqueReadingsMap = new Map()
              readings.forEach((point: any) => {
                uniqueReadingsMap.set(point.date, point)
              })
              const uniqueReadings = Array.from(uniqueReadingsMap.values())

              // Store all detail data in a single cache key
              queryClient.setQueryData(['consumptionDetail', selectedPDL], {
                success: true,
                data: {
                  meter_reading: {
                    interval_reading: uniqueReadings
                  }
                }
              })

              // Calculate period statistics for toast
              const dates = new Set(uniqueReadings.map((p: any) => p.date.split(' ')[0].split('T')[0]))
              const dayCount = dates.size
              const years = Math.floor(dayCount / 365)
              const remainingDays = dayCount % 365
              const yearsText = years > 0 ? `${years} an${years > 1 ? 's' : ''}` : ''
              const daysText = remainingDays > 0 ? `${remainingDays} jour${remainingDays > 1 ? 's' : ''}` : ''
              const periodText = [yearsText, daysText].filter(Boolean).join(' et ')

              updateConsumptionStatus({
                detail: 'success',
                detailProgress: { current: 1, total: 1 }
              })

              toast.success(`Consommation d√©taill√©e: ${periodText}, ${uniqueReadings.length} points`, { duration: 4000 })
            } else if (batchData?.error) {
              updateConsumptionStatus({ detail: 'error' })
              if (batchData.error.code === 'PARTIAL_DATA') {
                toast.success(batchData.error.message, { duration: 4000, icon: '‚ö†Ô∏è' })
              } else {
                toast.error(batchData.error.message || 'Erreur donn√©es d√©taill√©es de consommation')
              }
            }
          } catch (error: any) {
            logger.log('Error fetching consumption detail batch:', error)
            updateConsumptionStatus({ detail: 'error' })
            toast.error(`Erreur donn√©es d√©taill√©es de consommation: ${error?.response?.data?.error?.message || error.message}`)
          }
        })()
      )
    }

    // === PRODUCTION DATA ===
    // Only fetch production data when on production page or 'all' context
    // For linked production PDLs, ONLY fetch production data (never consumption)
    if (shouldFetchProduction) {
      // Determine which PDL to use for production data
      let productionPdlUsagePointId: string | null = null

      if (selectedPDLDetails.has_production) {
        // This PDL has production capability
        productionPdlUsagePointId = selectedPDL
      } else if (selectedPDLDetails.linked_production_pdl_id) {
        // This is a consumption PDL linked to a production PDL
        // Find the production PDL in the list to get its usage_point_id
        const productionPDL = allPDLs.find(p => p.id === selectedPDLDetails.linked_production_pdl_id)
        if (productionPDL) {
          productionPdlUsagePointId = productionPDL.usage_point_id
          logger.log(`Using linked production PDL: ${productionPdlUsagePointId} (only production data, not consumption)`)
        }
      }

    if (productionPdlUsagePointId) {
      logger.log(`Fetching production data for PDL: ${productionPdlUsagePointId}`)

      // Invalidate existing production queries
      queryClient.invalidateQueries({ queryKey: ['productionDaily', productionPdlUsagePointId] })

      // Fetch production daily data (3 years)
      updateProductionStatus({ daily: 'loading' })
      fetchPromises.push(
        (async () => {
          try {
            logger.log(`Fetching production daily: ${startDate3y} ‚Üí ${endDate}`)
            const dailyData = await enedisApi.getProductionDaily(productionPdlUsagePointId, {
              start: startDate3y,
              end: endDate,
              use_cache: true,
            })

            if (dailyData?.success) {
              queryClient.setQueryData(['productionDaily', productionPdlUsagePointId], dailyData)
              updateProductionStatus({ daily: 'success' })
              logger.log('Production daily data fetched successfully')
            } else {
              updateProductionStatus({ daily: 'error' })
            }
          } catch (error: any) {
            logger.log('Error fetching production daily:', error)
            updateProductionStatus({ daily: 'error' })
            toast.error(`Erreur donn√©es quotidiennes de production: ${error?.response?.data?.error?.message || error.message}`)
          }
        })()
      )

      // Fetch production detail batch (2 years)
      updateProductionStatus({ detail: 'loading', detailProgress: { current: 0, total: 1 } })
      fetchPromises.push(
        (async () => {
          try {
            logger.log(`Fetching production detail batch: ${startDate2y} ‚Üí ${endDate}`)
            const batchData = await enedisApi.getProductionDetailBatch(productionPdlUsagePointId, {
              start: startDate2y,
              end: endDate,
              use_cache: true,
            })

            if (batchData?.success && (batchData as any)?.data?.meter_reading?.interval_reading) {
              const readings = (batchData as any).data.meter_reading.interval_reading

              // Deduplicate readings using a Map with timestamp as key
              const uniqueReadingsMap = new Map()
              readings.forEach((point: any) => {
                uniqueReadingsMap.set(point.date, point)
              })
              const uniqueReadings = Array.from(uniqueReadingsMap.values())

              // Store all detail data in a single cache key
              queryClient.setQueryData(['productionDetail', productionPdlUsagePointId], {
                success: true,
                data: {
                  meter_reading: {
                    interval_reading: uniqueReadings
                  }
                }
              })

              // Calculate period statistics for toast
              const dates = new Set(uniqueReadings.map((p: any) => p.date.split(' ')[0].split('T')[0]))
              const dayCount = dates.size
              const years = Math.floor(dayCount / 365)
              const remainingDays = dayCount % 365
              const yearsText = years > 0 ? `${years} an${years > 1 ? 's' : ''}` : ''
              const daysText = remainingDays > 0 ? `${remainingDays} jour${remainingDays > 1 ? 's' : ''}` : ''
              const periodText = [yearsText, daysText].filter(Boolean).join(' et ')

              updateProductionStatus({
                detail: 'success',
                detailProgress: { current: 1, total: 1 }
              })

              toast.success(`Production d√©taill√©e: ${periodText}, ${uniqueReadings.length} points`, { duration: 4000 })
            } else if (batchData?.error) {
              updateProductionStatus({ detail: 'error' })
              if (batchData.error.code === 'PARTIAL_DATA') {
                toast.success(batchData.error.message, { duration: 4000, icon: '‚ö†Ô∏è' })
              } else {
                toast.error(batchData.error.message || 'Erreur donn√©es d√©taill√©es de production')
              }
            }
          } catch (error: any) {
            logger.log('Error fetching production detail batch:', error)
            updateProductionStatus({ detail: 'error' })
            toast.error(`Erreur donn√©es d√©taill√©es de production: ${error?.response?.data?.error?.message || error.message}`)
          }
        })()
      )
    }
    } // End of shouldFetchProduction block

    // Wait for all fetch promises to complete in parallel
    await Promise.all(fetchPromises)

    logger.log('Unified data fetch completed')

    // Show a toast to indicate cache persistence is happening
    const persistToast = toast.loading('üíæ Mise en cache des donn√©es...', { duration: 3000 })

    // Wait a bit for React Query Persist to save to localStorage
    // This gives time for the persistence mechanism to complete
    setTimeout(() => {
      toast.dismiss(persistToast)
      toast.success('‚úÖ Donn√©es mises en cache avec succ√®s !', { duration: 3000 })

      // Broadcast cache update to other tabs
      logger.log('[UnifiedFetch] Broadcasting CACHE_UPDATED to other tabs')
      broadcast({
        type: 'CACHE_UPDATED',
        timestamp: Date.now(),
        source: 'unified-fetch'
      })
      logger.log('[UnifiedFetch] Broadcast sent')
    }, 1500)
  }, [selectedPDL, selectedPDLDetails, allPDLs, pageContext, queryClient, updateConsumptionStatus, updateProductionStatus, resetLoadingStatus, broadcast])

  return {
    fetchAllData,
  }
}
